{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Flow Intersection Deadend Transform\n",
    "Extracts the flow (proportional to width of street), intersection and deadend masks and concatenates them with the original mask as 3 new channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.io import ImageReadMode\n",
    "\n",
    "from skimage.morphology import medial_axis, skeletonize\n",
    "from scipy.ndimage import distance_transform_edt, gaussian_filter, binary_erosion, binary_dilation\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.stats import norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_kern(size, window):\n",
    "    ax = np.linspace(-(size - 1) / 2, (size - 1) / 2., size)\n",
    "    ax = abs(ax)\n",
    "    y = 1.0 - norm(window, size/8.0).cdf(ax)\n",
    "    \n",
    "    kernel = np.outer(y, y)\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_close_centers(centers, min_width = 0.0):\n",
    "    merged = True\n",
    "    while merged:\n",
    "        merged = False\n",
    "        for yo,xo,wo in centers:\n",
    "            mean_y = 0\n",
    "            mean_x = 0\n",
    "            mean_w = 0\n",
    "\n",
    "            similar_centers = [] # including (yo,xo,wo)\n",
    "            for c in centers: \n",
    "                yc,xc,wc = c\n",
    "                if (yc-yo)**2 + (xc-xo)**2 < (max(wo + wc, min_width))**2:\n",
    "                    similar_centers.append(c)\n",
    "                    mean_y += yc\n",
    "                    mean_x += xc\n",
    "                    mean_w += wc\n",
    "\n",
    "            cnt = len(similar_centers)\n",
    "            if cnt > 1: # not only (yo,xo,wo) => merge centers\n",
    "                for c in similar_centers:\n",
    "                    centers.remove(c)\n",
    "                \n",
    "                centers.append((mean_y / cnt, mean_x / cnt, mean_w / cnt))\n",
    "                merged = True\n",
    "                break\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centers_mask(centers, h, w, min_width = 0.0, minmax_scaling=True):\n",
    "    mask = np.zeros(shape=(h,w))\n",
    "    for (yc,xc,wc) in centers:\n",
    "        yc,xc = round(yc),round(xc)\n",
    "        wc = max(min_width, wc)\n",
    "        gaussian = cum_kern(int(4*wc), wc)\n",
    "        start_y = yc - gaussian.shape[0] // 2\n",
    "        start_x = xc - gaussian.shape[1] // 2\n",
    "\n",
    "        height = gaussian.shape[0]\n",
    "        width = gaussian.shape[1]\n",
    "        end_y = start_y + height\n",
    "        end_x = start_x + width\n",
    "\n",
    "        trunc_start_y = 0\n",
    "        trunc_start_x = 0\n",
    "        if start_y < 0:\n",
    "            trunc_start_y = abs(start_y)\n",
    "            start_y = 0\n",
    "        if start_x < 0:\n",
    "            trunc_start_x = abs(start_x)\n",
    "            start_x = 0\n",
    "\n",
    "        if end_y >= h:\n",
    "            end_y = h - 1\n",
    "            height = end_y - start_y\n",
    "        if end_x >= w:\n",
    "            end_x = w - 1\n",
    "            width = end_x - start_x\n",
    "\n",
    "        current_mask = np.zeros(shape=(h,w))\n",
    "        current_mask[start_y:end_y, start_x:end_x] = gaussian[trunc_start_y:trunc_start_y+height, trunc_start_x:trunc_start_x+width] * wc\n",
    "        \n",
    "        mask = np.maximum(mask, current_mask)\n",
    "    \n",
    "    if minmax_scaling:\n",
    "        mask = (mask - mask.min()) / max((mask.max() - mask.min()), 1.0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(mask, smooth_mask_iterations: int = 1, smooth_flow: float = None, min_width: float = 5.0, include_skeleton: bool = False):\n",
    "    padding = mask.shape[0] // 4\n",
    "    mask = F.pad(torch.Tensor(mask).unsqueeze(0), pad=(padding,padding,padding,padding), mode='replicate').squeeze().numpy()\n",
    "\n",
    "    # removes minor edges that cause additional branch in skeleton\n",
    "    for i in range(smooth_mask_iterations):\n",
    "        mask = binary_erosion(binary_dilation(mask, iterations=round(min_width)), iterations=round(min_width)) \n",
    "    mask = 1.0 * mask # convert to float\n",
    "\n",
    "    # perform skeletonization\n",
    "    skeleton = medial_axis(mask)\n",
    "\n",
    "    # compute distance to edge of road\n",
    "    # dist_to_edge = distance_transform_edt(binary_erosion(mask))\n",
    "    outline = mask - binary_erosion(mask) # using this, so we don't lose very thin connections\n",
    "    dist_to_edge = distance_transform_edt(1.0 - outline)\n",
    "\n",
    "    # compute distance to center of road\n",
    "    r, idx_center = distance_transform_edt(1.0 - skeleton, return_indices=True)\n",
    "\n",
    "    # FLOW\n",
    "    # TODO: separate into x,y component?\n",
    "    h,w = mask.shape\n",
    "    flow = np.zeros(shape=(h,w))\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            center_y,center_x = idx_center[0][y,x],idx_center[1][y,x]\n",
    "            center_width = dist_to_edge[center_y,center_x] + 0.0001\n",
    "            flow[y,x] = max(0, 1.0 - ((center_y - y)**2 + (center_x - x)**2) / (center_width)**2) * center_width**(0.05)\n",
    "\n",
    "    if smooth_flow:\n",
    "        flow = gaussian_filter(flow, smooth_flow)\n",
    "\n",
    "    edge_kernel = np.array([\n",
    "        [1,1,1],\n",
    "        [1,0,1],\n",
    "        [1,1,1]\n",
    "    ])\n",
    "    connections = skeleton * convolve2d(1.0 * skeleton, edge_kernel, mode='same')\n",
    "\n",
    "    # INTERSECTIONS\n",
    "    intersection_centers = [] \n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            if connections[y,x] <= 2: # not an intersection\n",
    "                continue\n",
    "            center_y,center_x = idx_center[0][y,x],idx_center[1][y,x]\n",
    "            center_width = dist_to_edge[center_y,center_x] + 0.0001\n",
    "            if center_width < 2: # likely an artifact\n",
    "                continue\n",
    "\n",
    "            intersection_centers.append((center_y, center_x, center_width))\n",
    "\n",
    "    intersection_centers = merge_close_centers(intersection_centers, min_width)\n",
    "    intersection = centers_mask(intersection_centers, h, w, min_width)\n",
    "\n",
    "    # DEADENDS\n",
    "    deadend_centers = [] \n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            if connections[y,x] != 1: # not an endpoint\n",
    "                continue\n",
    "            center_y,center_x = idx_center[0][y,x],idx_center[1][y,x]\n",
    "            center_width = dist_to_edge[center_y,center_x] + 0.0001\n",
    "            # if center_width < 0.01:\n",
    "            #     continue\n",
    "\n",
    "            deadend_centers.append((center_y, center_x, center_width))\n",
    "\n",
    "    # print([(dy,dx,dw) for (dy,dx,dw) in intersection_centers if dx - padding >= 0 and dx - padding < w and dy - padding >= 0 and dy - padding < h ])\n",
    "    # print([(dy,dx,dw) for (dy,dx,dw) in deadend_centers if dx - padding >= 0 and dx - padding < w and dy - padding >= 0 and dy - padding < h ])\n",
    "    \n",
    "    # remove deadends that are very close to intersections\n",
    "    to_remove = []\n",
    "    for c in deadend_centers:\n",
    "        dy,dx,dw = c\n",
    "        for iy,ix,iw in intersection_centers:\n",
    "            if (dy-iy)**2 + (dx-ix)**2 < 2 * (max(dw + iw, min_width))**2:\n",
    "                to_remove.append(c)\n",
    "    for c in set(to_remove):\n",
    "        deadend_centers.remove(c)\n",
    "    \n",
    "    # remove deadends that are very close to other deadends\n",
    "    to_remove = []\n",
    "    for d in deadend_centers:\n",
    "        dy,dx,dw = d\n",
    "        for o in deadend_centers:\n",
    "            oy,ox,ow = o\n",
    "            if dy == oy and dx == ox: continue # ignore itself\n",
    "            if (dy-oy)**2 + (dx-ox)**2 < 2 * (max((dw + ow), min_width))**2:\n",
    "                to_remove.append(d)\n",
    "    for c in set(to_remove):\n",
    "        deadend_centers.remove(c)\n",
    "        \n",
    "    deadend_centers = merge_close_centers(deadend_centers, 2 * min_width)\n",
    "\n",
    "    deadend = centers_mask(deadend_centers, h, w, min_width)\n",
    "\n",
    "    if include_skeleton:\n",
    "        return flow[padding:-padding,padding:-padding], intersection[padding:-padding,padding:-padding], deadend[padding:-padding,padding:-padding], skeleton[padding:-padding,padding:-padding]\n",
    "    return flow[padding:-padding,padding:-padding], intersection[padding:-padding,padding:-padding], deadend[padding:-padding,padding:-padding]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOOTH_ITERATIONS = 5 # how many dilation&erosion iterations should be performed before skeletonization\n",
    "SMOOTH_FLOW_SIGMA = 5.0 # sigma of gaussian smoothing that will be applied to flow mask\n",
    "LOWER_BOUND_WIDTH = 5.0 # streets below this width will be automatically treated as if they had this width\n",
    "\n",
    "DATA_FOLDER = 'data/data5k' # the masks of which dataset should be transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = os.path.join(DATA_FOLDER, 'groundtruth')\n",
    "output_folder = os.path.join(DATA_FOLDER, 'transformed')\n",
    "\n",
    "out_folder = os.path.join(output_folder, 'mask_flow_intersection_deadend')\n",
    "os.makedirs(out_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(i, img_name):\n",
    "    in_path = os.path.join(base_folder, img_name)\n",
    "    descriptor = img_name.split('.')[0]\n",
    "    out_path = os.path.join(out_folder, f'{descriptor}')\n",
    "    mask = torchvision.io.read_image(in_path, mode=ImageReadMode.GRAY)/255.0\n",
    "    mask = mask.squeeze().numpy()\n",
    "\n",
    "    flow, intersection, deadend = convert(mask, SMOOTH_ITERATIONS, SMOOTH_FLOW_SIGMA, LOWER_BOUND_WIDTH)\n",
    "\n",
    "    mfid = np.stack([mask, flow, intersection, deadend]).astype(np.float16)\n",
    "    np.save(out_path, mfid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Parallel(n_jobs=8)(delayed(process)(i, img_name) for i,img_name in enumerate(os.listdir(base_folder)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 500\n",
    "inspect_path = f'data/data1k/transformed/mask_flow_intersection_deadend/boston_satimage_{i}.npy'\n",
    "mask, flow, intersection, deadend = np.load(inspect_path)\n",
    "\n",
    "fig,ax = plt.subplots(2,2)\n",
    "\n",
    "ax[0,0].imshow(mask)\n",
    "ax[0,0].axis(False)\n",
    "ax[0,1].imshow(flow)\n",
    "ax[0,1].axis(False)\n",
    "ax[1,0].imshow(intersection)\n",
    "ax[1,0].axis(False)\n",
    "ax[1,1].imshow(deadend)\n",
    "ax[1,1].axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 69\n",
    "inspect_path = f'data/training/groundtruth/satimage_{i}.png'\n",
    "mask = torchvision.io.read_image(inspect_path, mode=ImageReadMode.GRAY)/255.0\n",
    "mask = mask.squeeze().numpy()\n",
    "\n",
    "flow, intersection, deadend, skeleton = convert(mask, SMOOTH_ITERATIONS, SMOOTH_FLOW_SIGMA, LOWER_BOUND_WIDTH, True)\n",
    "\n",
    "fig,ax = plt.subplots(2,3)\n",
    "\n",
    "ax[0,0].imshow(mask)\n",
    "ax[0,0].axis(False)\n",
    "ax[0,1].imshow(flow)\n",
    "ax[0,1].axis(False)\n",
    "ax[0,2].imshow(skeleton)\n",
    "ax[0,2].axis(False)\n",
    "ax[1,0].imshow(intersection)\n",
    "ax[1,0].axis(False)\n",
    "ax[1,1].imshow(deadend)\n",
    "ax[1,1].axis(False)\n",
    "ax[1,2].axis(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
