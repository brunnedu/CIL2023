{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T16:46:50.612533Z",
     "start_time": "2023-05-03T16:46:50.324411Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from src.models.unet.backbones import Resnet18Backbone\n",
    "import torchvision\n",
    "from PIL import Image, ImageFilter\n",
    "from src.dataset import SatelliteDataset, SatelliteDatasetRun\n",
    "from src.utils import load_model\n",
    "from src.models.unet.unet import UNet\n",
    "from src.models.unet.blocks import UpBlock\n",
    "from torchvision.io import ImageReadMode\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T21:19:23.693657Z",
     "start_time": "2023-04-26T21:19:23.689462Z"
    }
   },
   "source": [
    "# Shadow Removal\n",
    "Labeled test data from: https://github.com/RSrscoder/AISD\n",
    "\n",
    "Images were converted from TIF to PNG, so we can support torchvision.io.read_image (see SatelliteDataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T16:46:54.340989Z",
     "start_time": "2023-05-03T16:46:54.315800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_data = SatelliteDatasetRun(data_dir=\"./data/test\", hist_equalization=False)\n",
    "dataloader = DataLoader(test_data, batch_size=1, shuffle=True) # batch_size must be 1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T16:47:30.207034Z",
     "start_time": "2023-05-03T16:47:29.650033Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(backbone=Resnet18Backbone(), up_block_ctor=lambda ci: UpBlock(ci, up_mode='upconv'))\n",
    "state_dict = torch.load('./out/shadows_2023-04-04_17-00-58/best_model.pth.tar')\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def remove_shadows(img: Image, mask: np.array):\n",
    "    \"\"\"Removes shadow mask from img.\n",
    "\n",
    "    :param img: Pillow Image of the statellite image.\n",
    "    :param mask: Numpy boolean array\n",
    "    \"\"\"\n",
    "    # display\n",
    "    display(img)\n",
    "    display(Image.fromarray((mask*255).astype(np.uint8)))\n",
    "\n",
    "    # shadow removal via HSV\n",
    "    mult_mask = (1 + mask*2)\n",
    "    img_hsv = np.asarray(img.convert(\"HSV\")).copy()\n",
    "    img_hsv[..., 2] = np.clip(img_hsv[..., 2] * mult_mask, 0, 255)\n",
    "    display(Image.fromarray(img_hsv, \"HSV\").convert(\"RGB\"))\n",
    "\n",
    "    img_test = np.asarray(img).copy()\n",
    "    img_test[...,0] = np.clip(img_test[...,0] * mult_mask, 0, 255)\n",
    "    img_test[...,1] = np.clip(img_test[...,1] * mult_mask, 0, 255)\n",
    "    img_test[...,2] = np.clip(img_test[...,2] * mult_mask, 0, 255)\n",
    "    display(Image.fromarray(img_test))\n",
    "\n",
    "img = Image.open(\"data/shadows/images/chicago33_sub11.png\")\n",
    "mask = np.array(Image.open(\"data/shadows/groundtruth/chicago33_sub11.png\"))\n",
    "print(mask)\n",
    "remove_shadows(img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def remove_shadows(img: Image, mask: np.array):\n",
    "    \"\"\"Removes shadow mask from img.\n",
    "\n",
    "    :param img: Pillow Image of the statellite image.\n",
    "    :param mask: Numpy boolean array\n",
    "    \"\"\"\n",
    "    # display\n",
    "    #display(img)\n",
    "    img_array = np.array(img)\n",
    "    display(Image.fromarray((mask*255).astype(np.uint8)))\n",
    "    edge_img = cv2.Canny((mask*255).astype(np.uint8), 100, 100, apertureSize=3)\n",
    "\n",
    "    lines = cv2.HoughLinesP(edge_img, 10, np.pi / 180, 50).squeeze()\n",
    "    normal_vectors = np.zeros_like(lines)\n",
    "    img_norm = img_array.copy()\n",
    "    for index, line in enumerate(lines):\n",
    "        x1, y1, x2, y2 = line\n",
    "        x = x2 - x1\n",
    "        y = y2 - y1\n",
    "        cv2.line(img_norm, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        # rotate the line by 90 degree to get the normal vector\n",
    "        cv2.line(img_norm, (x1, y1), (x1+y, y1-x), (0, 255, 0), 2)\n",
    "        normal_vectors[index] = np.array((x1, y1, x1+y, y1-x))\n",
    "\n",
    "    display(Image.fromarray(edge_img))\n",
    "    display(Image.fromarray(img_norm))\n",
    "\n",
    "\n",
    "    # using normal vectors we define a function mapping from 20 pixels outside of the shadow to\n",
    "    # inside of the shadow\n",
    "    return\n",
    "\n",
    "    # each color has a width of 2 and a height of 10 for the composite\n",
    "    composite = np.zeros([100, len(normal_vectors)*2,3],dtype=np.uint8)\n",
    "    org = img_array.copy()\n",
    "    print(org.shape)\n",
    "    height, width, _ = org.shape\n",
    "    print(org.shape)\n",
    "    for index, nv in enumerate(normal_vectors):\n",
    "        start_point = nv[:2]\n",
    "        vec = nv[2:]\n",
    "        uvec = vec / np.sqrt((vec**2).sum())\n",
    "        print(nv, start_point, vec, uvec)\n",
    "        outside = np.clip(start_point + 5*uvec, 0, height-1).astype(int)\n",
    "        inside = np.clip(start_point - 5*uvec, 0, width-1).astype(int)\n",
    "        print(img_array.shape, outside, inside)\n",
    "        outside_color = img_array[outside[0], outside[1]].tolist()  # required for opencv\n",
    "        inside_color = img_array[inside[0], inside[1]].tolist()\n",
    "        # change color from RGB to BGR\n",
    "        cv2.rectangle(composite, (index * 2, 0), (index*2 + 2, 50), [outside_color[2], outside_color[1], outside_color[0]])\n",
    "        cv2.rectangle(composite, (index * 2, 50), (index*2 + 2, 100), [inside_color[2], inside_color[1], inside_color[0]])\n",
    "\n",
    "        cv2.circle(org, outside, radius=0, color=(255,0,0), thickness=2)\n",
    "        cv2.circle(org, inside, radius=0, color=(0,255,0), thickness=2)\n",
    "\n",
    "    print(composite)\n",
    "    #cv2.imshow(\"test\", composite)\n",
    "    #cv2.waitKey()\n",
    "    display(Image.fromarray(composite))\n",
    "    display(Image.fromarray(org))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    display(Image.fromarray(edge_img))\n",
    "    display(Image.fromarray(img_array))\n",
    "\n",
    "\n",
    "\n",
    "img = Image.open(\"data/shadows/images/chicago33_sub11.png\")\n",
    "mask = np.array(Image.open(\"data/shadows/groundtruth/chicago33_sub11.png\"))\n",
    "remove_shadows(img, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShadowFormer\n",
    "\n",
    "Testing shadow removal using ShadowFormer pretrained on different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from src.ShadowFormer.model import ShadowFormer\n",
    "from collections import OrderedDict\n",
    "\n",
    "img_size = 400\n",
    "\n",
    "def load_checkpoint(model, weights, device):\n",
    "    checkpoint = torch.load(weights, map_location=device)\n",
    "    try:\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    except:\n",
    "        state_dict = checkpoint[\"state_dict\"]\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            name = k[7:] if 'module.' in k else k\n",
    "            new_state_dict[name] = v\n",
    "        model.load_state_dict(new_state_dict)\n",
    "\n",
    "def output_to_image(model_output):\n",
    "    rgb_restored = torch.clamp(model_output, 0, 1).detach().cpu().numpy().squeeze().transpose((1, 2, 0))\n",
    "    return (rgb_restored * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(img_size),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "srm_istd = ShadowFormer(img_size=img_size, embed_dim=32,win_size=10,token_projection=\"linear\",token_mlp=\"leff\")\n",
    "srm_istd_plus = ShadowFormer(img_size=img_size, embed_dim=32,win_size=10,token_projection=\"linear\",token_mlp=\"leff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "base_path = \"./data/shadows/\"\n",
    "filenames = os.listdir(os.path.join(base_path, \"images\"))\n",
    "\n",
    "# get 10 random images\n",
    "random.shuffle(filenames)\n",
    "n = 10\n",
    "filenames = filenames[:n]\n",
    "\n",
    "# load models\n",
    "load_checkpoint(srm_istd, \"./out/ISTD_model_latest.pth\", device=torch.device(\"cpu\"))\n",
    "_ = srm_istd.eval()\n",
    "\n",
    "load_checkpoint(srm_istd_plus, \"./out/ISTD_plus_model_latest.pth\", device=torch.device(\"cpu\"))\n",
    "_ = srm_istd_plus.eval()\n",
    "\n",
    "fig = plt.figure(figsize=(img_size*4 / 100, img_size*n / 100))\n",
    "axes = fig.subplots(nrows=n, ncols=4)\n",
    "\n",
    "for i, filename in enumerate(tqdm(filenames)):\n",
    "    pil_img = Image.open(os.path.join(base_path, \"images\", filename))\n",
    "    pil_mask = Image.open(os.path.join(base_path, \"groundtruth\", filename))\n",
    "\n",
    "    img = transform(pil_img).unsqueeze(0)\n",
    "    mask = transform(pil_mask).unsqueeze(0)\n",
    "\n",
    "    srm_istd_out = srm_istd(img, mask)\n",
    "    srm_istd_plus_out = srm_istd_plus(img, mask)\n",
    "\n",
    "    axes[i][0].imshow(pil_img)\n",
    "    axes[i][1].imshow(pil_mask)\n",
    "    axes[i][2].imshow(output_to_image(srm_istd_out))\n",
    "    axes[i][3].imshow(output_to_image(srm_istd_plus_out))\n",
    "\n",
    "\n",
    "plt.suptitle(\"ShadowFormer on dataset with groundtruth shadows\", y=.995)\n",
    "axes[0][0].set_title(\"Original\")\n",
    "axes[0][1].set_title(\"Mask\")\n",
    "axes[0][2].set_title(\"ISTD\")\n",
    "axes[0][3].set_title(\"ISTD+\")\n",
    "\n",
    "[axi.set_axis_off() for axi in axes.ravel()]   # turns off axes\n",
    "plt.axis(\"tight\")  # gets rid of white border\n",
    "plt.axis(\"image\")  # square up the image instead of filling the \"figure\" space\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shadow.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShadowFormer on road segmentation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "upscale = torchvision.transforms.Resize(400)\n",
    "n = 10\n",
    "fig = plt.figure(figsize=(img_size*4 / 100, img_size*n / 100))\n",
    "axes = fig.subplots(nrows=n, ncols=4)\n",
    "\n",
    "def pil_from_tensor(tensor_image, change_channels=False):\n",
    "    img = (tensor_image.squeeze().detach().numpy() * 255).astype(np.uint8)\n",
    "    return Image.fromarray(img.transpose(1,2,0) if change_channels else img)\n",
    "\n",
    "for i, (path, size, img) in enumerate(tqdm(dataloader, total=n)):\n",
    "    out = model(img).detach()\n",
    "    out_threshold = (out > 0.5).type(torch.FloatTensor)\n",
    "\n",
    "    # for shadow ShadowFormer use actual image without any transforms\n",
    "    img = Image.open(path[0]).convert(\"RGB\")  # assume size 400x400\n",
    "    img_transformed = transform(img).unsqueeze(0)\n",
    "\n",
    "    # upscale image and mask to 400x400 and remove shadow using ShadowFormer trained on ISTD\n",
    "    out_threshold_scaled = upscale(out_threshold)\n",
    "    removed_shadow = srm_istd(img_transformed, out_threshold_scaled)\n",
    "\n",
    "    axes[i][0].imshow(img)\n",
    "    axes[i][1].imshow(pil_from_tensor(upscale(out)))\n",
    "    axes[i][2].imshow(pil_from_tensor(out_threshold_scaled))\n",
    "    axes[i][3].imshow(pil_from_tensor(removed_shadow, change_channels=True))\n",
    "\n",
    "    if i == n - 1:\n",
    "        break\n",
    "\n",
    "\n",
    "plt.suptitle(\"ShadowFormer on road segmentation test dataset\", y=.995)\n",
    "axes[0][0].set_title(\"Original\")\n",
    "axes[0][1].set_title(\"Raw Mask\")\n",
    "axes[0][2].set_title(\"Threshold Mask (t=0.5)\")\n",
    "axes[0][3].set_title(\"ShadowFormer (ISTD)\")\n",
    "\n",
    "[axi.set_axis_off() for axi in axes.ravel()]   # turns off axes\n",
    "plt.axis(\"tight\")  # gets rid of white border\n",
    "plt.axis(\"image\")  # square up the image instead of filling the \"figure\" space\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shadow_test_dataset.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
