{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision\n",
    "from torchvision.io import ImageReadMode\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction\n",
    "Reconstructs a mask from angle, width & distance data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders should contain mean/ and std/ subfolders\n",
    "angle_folder = \"out/madw_angle/run_training\"\n",
    "distance_folder = \"out/madw_dist/run_training_last\"\n",
    "width_folder = \"out/madw_width/run_training_last\"\n",
    "mask_prior_folder = None # \"out/madw_prior/run_test\" # set to None if you don't want to include prior masks\n",
    "out_folder = \"out/madw/training\"\n",
    "\n",
    "RESIZE_FACTOR = 0.25\n",
    "BINARIZE_OUTPUT = True\n",
    "BINARIZATION_PERCENTILE = 75 # in %\n",
    "MASK_PRIOR_THRESHOLD = 0.5\n",
    "OVERWRITE = False # whether to overwrite existing priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This must be the same as in ADW-Transform!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING = 25\n",
    "SMOOTH_ANGLE = 2.0 # None to disable\n",
    "SMOOTH_WIDTH = 1.0 # None to disable\n",
    "SMOOTH_MASK_ITERATIONS = 3\n",
    "\n",
    "# the image size that the model will be working on (matters for distance prediction!)\n",
    "TARGET_SIZE = (224,224) \n",
    "# leave at (400,400) if doing cropping\n",
    "# use (224,224) if rescaling\n",
    "\n",
    "NORM_ANGLE_MIN, NORM_ANGLE_DELTA = -3.15, 6.3\n",
    "NORM_DISTANCE_MIN, NORM_DISTANCE_DELTA = 0, np.sqrt(2*(TARGET_SIZE[0] + 2*PADDING)**2) + 1\n",
    "NORM_WIDTH_MIN, NORM_WIDTH_DELTA = 0, TARGET_SIZE[0] / 4 # this might cause some overflows if chosen too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor_interpolation_2D(arr, target_size):\n",
    "    current_size = arr.shape\n",
    "    row_ratio, col_ratio = np.array(target_size)/np.array(current_size)\n",
    "\n",
    "    row_idx = (np.ceil(range(1, 1 + int(current_size[0]*row_ratio))/row_ratio) - 1).astype(int)\n",
    "    col_idx = (np.ceil(range(1, 1 + int(current_size[1]*col_ratio))/col_ratio) - 1).astype(int)\n",
    "\n",
    "    return arr[:,row_idx][col_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2pol(x, y, m_alpha):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    if m_alpha - phi > (2*np.pi + phi) - m_alpha:\n",
    "        phi = 2*np.pi + phi\n",
    "    return(rho, phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_to_true(angle_mean, angle_std, distance_mean, distance_std, width_mean, width_std, \n",
    "                 angle_min, angle_delta, distance_min, distance_delta, width_min, width_delta):\n",
    "    angle_mean = angle_mean * angle_delta + angle_min\n",
    "    angle_std = angle_std * angle_delta\n",
    "\n",
    "    distance_mean = distance_mean * distance_delta + distance_min\n",
    "    distance_std = distance_std * distance_delta\n",
    "\n",
    "    width_mean = width_mean * width_delta + width_min\n",
    "    width_std = width_std * width_delta    \n",
    "\n",
    "    return angle_mean, angle_std, distance_mean, distance_std, width_mean, width_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample(name):\n",
    "    angle_mean = (torchvision.io.read_image(os.path.join(angle_folder, 'mean', name), mode=ImageReadMode.GRAY).squeeze()/255.0).numpy()\n",
    "    angle_std = (torchvision.io.read_image(os.path.join(angle_folder, 'std', name), mode=ImageReadMode.GRAY).squeeze()/255.0).numpy()\n",
    "    distance_mean = (torchvision.io.read_image(os.path.join(distance_folder, 'mean', name), mode=ImageReadMode.GRAY).squeeze()/255.0).numpy()\n",
    "    distance_std = (torchvision.io.read_image(os.path.join(distance_folder, 'std', name), mode=ImageReadMode.GRAY).squeeze()/255.0).numpy()\n",
    "    width_mean = (torchvision.io.read_image(os.path.join(width_folder, 'mean', name), mode=ImageReadMode.GRAY).squeeze()/255.0).numpy()\n",
    "    width_std = (torchvision.io.read_image(os.path.join(width_folder, 'std', name), mode=ImageReadMode.GRAY).squeeze()/255.0).numpy()\n",
    "\n",
    "    return norm_to_true(angle_mean, angle_std, distance_mean, distance_std, width_mean, width_std, \n",
    "                        NORM_ANGLE_MIN, NORM_ANGLE_DELTA, NORM_DISTANCE_MIN, NORM_DISTANCE_DELTA, NORM_WIDTH_MIN, NORM_WIDTH_DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(angle_mean, angle_std, distance_mean, distance_std, width_mean, width_std):\n",
    "    def print_info(name, data_mean, data_std):\n",
    "        print(f\"{name} Mean: min {data_mean.min()}, max {data_mean.max()}, mean {data_mean.mean()}\")\n",
    "        print(f\"{name} Std: min {data_std.min()}, max {data_std.max()}, mean {data_std.mean()}\")\n",
    "\n",
    "    fig,axs = plt.subplots(2,3)\n",
    "    for ax in axs.flat:\n",
    "        ax.axis('off')\n",
    "\n",
    "    axs[0,0].set_title(\"angle\")\n",
    "    axs[0,0].imshow(angle_mean)\n",
    "    axs[1,0].imshow(angle_std)\n",
    "\n",
    "    axs[0,1].set_title(\"distance\")\n",
    "    axs[0,1].imshow(distance_mean)\n",
    "    axs[1,1].imshow(distance_std)\n",
    "\n",
    "    axs[0,2].set_title(\"width\")\n",
    "    axs[0,2].imshow(width_mean)\n",
    "    axs[1,2].imshow(width_std)\n",
    "\n",
    "    print_info(\"Angle\", angle_mean, angle_std)\n",
    "    print_info(\"Distance\", distance_mean, distance_std)\n",
    "    print_info(\"Width\", width_mean, width_std)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp_outliers(data, perc):\n",
    "    # perc from 0 - 100\n",
    "    thresh_low = np.percentile(data, perc)\n",
    "    thresh_high = np.percentile(data, 100 - perc)\n",
    "    data[data < thresh_low] = thresh_low\n",
    "    data[data > thresh_high] = thresh_high\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_votes(angle_mean, angle_std, dist_mean, dist_std, width_mean, width_std, resize_factor = 0.25):\n",
    "    original_size = angle_mean.shape[-1]\n",
    "    # subsample\n",
    "    size = round(resize_factor * original_size)\n",
    "\n",
    "    res_total_influence = np.zeros((size,size))\n",
    "    vote_width_mean = np.zeros((size,size))\n",
    "    vote_width_std = np.zeros((size,size))\n",
    "\n",
    "    angle_mean = nearest_neighbor_interpolation_2D(angle_mean, (size,size)) # invariant to scaling\n",
    "    angle_std = nearest_neighbor_interpolation_2D(angle_std, (size,size))\n",
    "    dist_mean = nearest_neighbor_interpolation_2D(dist_mean, (size,size)) * resize_factor # k * X ~ N(k * m, (k*s)^2)\n",
    "    dist_std = nearest_neighbor_interpolation_2D(dist_std, (size,size)) * resize_factor\n",
    "    width_mean = nearest_neighbor_interpolation_2D(width_mean, (size,size)) # keep original scale\n",
    "    width_std = nearest_neighbor_interpolation_2D(width_std, (size,size))\n",
    "\n",
    "    # precompute distances and angles\n",
    "    indices_ext = np.array([range(-size+1, size)]).T @ np.ones((1,2*size-1))\n",
    "    dists = np.sqrt(np.sum(np.stack([indices_ext**2, indices_ext.T**2], axis=-1), axis=-1))\n",
    "\n",
    "    indices_2d = np.stack([indices_ext, indices_ext.T], axis=-1)\n",
    "    angles = np.arctan2(indices_2d[:,:,0], indices_2d[:,:,1])\n",
    "\n",
    "    res_total_influence = np.zeros((size,size))\n",
    "    vote_width_mean = np.zeros((size,size))\n",
    "    vote_width_var = np.ones((size,size))\n",
    "\n",
    "    # precompute constants\n",
    "    joint_norm_std = 1 / (2 * np.pi * angle_std * dist_std)\n",
    "\n",
    "    for y in range(size):\n",
    "        for x in range(size):\n",
    "            # (y,x) are pixel u from the report\n",
    "            # we do vectorization over all pixels t\n",
    "\n",
    "            # the votes of pixel u\n",
    "            local_angle_mean = angle_mean[y,x]\n",
    "            local_angle_std = angle_std[y,x]\n",
    "            local_dist_mean = dist_mean[y,x]\n",
    "            local_dist_std = dist_std[y,x]\n",
    "            local_width_mean = width_mean[y,x]\n",
    "            local_width_var = width_std[y,x] * width_std[y,x]\n",
    "            \n",
    "            # load the precomputed angles and distances based on the coordinates of u\n",
    "            local_dists = dists[size-1-y:size-1-y+size,size-1-x:size-1-x+size]\n",
    "            local_angles = angles[size-1-y:size-1-y+size,size-1-x:size-1-x+size]\n",
    "\n",
    "            # compute the closest angle to the local angle (so it's always < 180Â°). This is important bc it always gives the maximum possible influence.\n",
    "            closest_local_angles = local_angles + np.sign(local_angle_mean - local_angles) * (np.abs(local_angle_mean - local_angles) > np.pi) * 2 * np.pi\n",
    "\n",
    "            # influence map (prob that u points to any other t), basically elementwise gaussian\n",
    "            influence = joint_norm_std[y,x] * np.exp(-0.5 * (((closest_local_angles - local_angles) / local_angle_std)**2 + ((local_dists - local_dist_mean) / local_dist_std)**2))\n",
    "\n",
    "            res_total_influence += influence\n",
    "            vote_width_mean += influence * local_width_mean\n",
    "            vote_width_var += influence * (local_width_var + local_width_mean**2) # work in var space, as then we can pull out the normalizing constant (total influence on any pixel t)\n",
    "\n",
    "    # divide by normalizing constant (basically normalizing influence to sum to 1)\n",
    "    vote_width_mean /= res_total_influence \n",
    "    vote_width_var /= res_total_influence \n",
    "\n",
    "    # finally subtract mean^2\n",
    "    vote_width_var -= vote_width_mean**2 \n",
    "\n",
    "    vote_width_std = np.sqrt(vote_width_var)\n",
    "    return vote_width_mean, vote_width_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_mask(vote_width_mean, vote_width_std, resize_factor = 0.25, mask_prior = None, prior_threshold = 0.5):\n",
    "    size = vote_width_mean.shape[-1]\n",
    "\n",
    "    # rescale the aggregated votes (since we are subsampling)\n",
    "    vote_width_mean *= resize_factor\n",
    "    vote_width_std *= resize_factor \n",
    "\n",
    "    # precompute the distances\n",
    "    indices_ext = np.array([range(-size+1, size)]).T @ np.ones((1,2*size-1))\n",
    "    dists = np.sqrt(np.sum(np.stack([indices_ext**2, indices_ext.T**2], axis=-1), axis=-1))\n",
    "\n",
    "    res_mask = np.zeros((size,size))\n",
    "\n",
    "    for y in range(size):\n",
    "        for x in range(size):\n",
    "            # (y,x) is pixel t from report\n",
    "\n",
    "            # ignore all votes with width close to 0 (=> speed up)\n",
    "            if vote_width_mean[y,x] < 0.1: \n",
    "                continue\n",
    "\n",
    "            # if you include a prior mask, only consider those pixels that are already masked\n",
    "            if mask_prior is not None:\n",
    "                if mask_prior[y,x] < prior_threshold:\n",
    "                    continue\n",
    "            \n",
    "            norm = stats.norm(vote_width_mean[y,x], vote_width_std[y,x])\n",
    "            local_dists = dists[size-1-y:size-1-y+size,size-1-x:size-1-x+size]\n",
    "            \n",
    "            # compute chance that t points to any pixel s\n",
    "            prop_that_road = 1.0 - norm.cdf(local_dists)\n",
    "\n",
    "            # we additively construct the final mask\n",
    "            res_mask = np.maximum(res_mask, prop_that_road)\n",
    "\n",
    "    return res_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data\n",
    "Execute this code to run reconstruction with the specified masks. This process might take a while (took ~1h for 1k images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(i,img_name):\n",
    "    output_path = os.path.join(out_folder, img_name)\n",
    "    if not OVERWRITE and os.path.exists(output_path):\n",
    "        return\n",
    "    \n",
    "    angle_mean, angle_std, dist_mean, dist_std, width_mean, width_std = load_sample(img_name)\n",
    "    original_size = angle_mean.shape[-1]\n",
    "\n",
    "    dist_std /= 10.0 # seems to work better with lower dist, could be tuned further\n",
    "\n",
    "    vote_width_mean, vote_width_std = aggregate_votes(angle_mean, angle_std, dist_mean, dist_std, width_mean, width_std, resize_factor=RESIZE_FACTOR)\n",
    "\n",
    "    mask_prior = None\n",
    "    if mask_prior_folder is not None:\n",
    "        mask_prior = (torchvision.io.read_image(os.path.join(mask_prior_folder, img_name), mode=ImageReadMode.GRAY).squeeze()/255.0).numpy()\n",
    "        \n",
    "    res_mask = construct_mask(vote_width_mean, vote_width_std, resize_factor=RESIZE_FACTOR, mask_prior=mask_prior, prior_threshold=MASK_PRIOR_THRESHOLD)\n",
    "    \n",
    "    thresh_res_mask = res_mask\n",
    "    if BINARIZE_OUTPUT:\n",
    "        threshold = np.percentile(res_mask, BINARIZATION_PERCENTILE)\n",
    "        thresh_res_mask = (res_mask > threshold) * 1.0\n",
    "\n",
    "    output = nearest_neighbor_interpolation_2D(thresh_res_mask, (original_size,original_size))\n",
    "    cv2.imwrite(output_path, output * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(out_folder, exist_ok=True)\n",
    "r = Parallel(n_jobs=8)(delayed(process)(i, img_name) for i,img_name in enumerate(os.listdir(os.path.join(angle_folder, 'mean'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual\n",
    "This section can be used to inspect the reconstruction of a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_mean, angle_std, dist_mean, dist_std, width_mean, width_std = load_sample(\"satimage_144.png\")\n",
    "outlier_perc = 2.5\n",
    "# angle_mean = clamp_outliers(angle_mean, outlier_perc)\n",
    "# angle_std = clamp_outliers(angle_std, outlier_perc)\n",
    "# dist_mean = clamp_outliers(dist_mean, outlier_perc)\n",
    "# dist_std = clamp_outliers(dist_std, outlier_perc)\n",
    "# width_mean = clamp_outliers(width_mean, outlier_perc)\n",
    "# width_std = clamp_outliers(width_std, outlier_perc)\n",
    "\n",
    "visualize_sample(angle_mean, angle_std, dist_mean, dist_std, width_mean, width_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
