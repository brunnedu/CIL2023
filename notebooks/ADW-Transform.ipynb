{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angle Distance Width Transform\n",
    "Transforms binary masks to corresponding (angle,distance,width)-masks where each pixel points to the closest center of the street (using polar coordinates) and how wide it believes the street to be at that point. The output will be stored in 3 subfolders: angle, distance, width\n",
    "\n",
    "\n",
    "#### Important Note: Renormalize before reconstruction!\n",
    "You must multiply with delta and then add the min for angle, distance, width before reconstruction! Otherwise the spatial dimensions will be wrong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import real, imag\n",
    "from PIL import ImageDraw as draw, Image\n",
    "\n",
    "import torchvision\n",
    "from torchvision.io import ImageReadMode\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skimage.morphology import medial_axis, skeletonize\n",
    "from scipy.ndimage import distance_transform_edt, gaussian_filter, binary_erosion, binary_closing\n",
    "from numpy import angle as anglef\n",
    "\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = 'data/data5k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING = 25\n",
    "SMOOTH_ANGLE = 2.0 # None to disable\n",
    "SMOOTH_WIDTH = 1.0 # None to disable\n",
    "SMOOTH_MASK_ITERATIONS = 3\n",
    "\n",
    "# the image size that the model will be working on (matters for distance prediction!)\n",
    "TARGET_SIZE = (224,224) \n",
    "# leave at (400,400) if doing cropping\n",
    "# use (224,224) if rescaling\n",
    "\n",
    "NORM_ANGLE_MIN, NORM_ANGLE_DELTA = -3.15, 6.3\n",
    "NORM_DISTANCE_MIN, NORM_DISTANCE_DELTA = 0, np.sqrt(2*(TARGET_SIZE[0] + 2*PADDING)**2) + 1\n",
    "NORM_WIDTH_MIN, NORM_WIDTH_DELTA = 0, TARGET_SIZE[0] / 4 # this might cause some overflows if chosen too small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_distance_angle_width(mask: np.ndarray, padding: int = 25, smooth_mask_iterations: int = 3,\n",
    "                          smooth_angle : float = None, smooth_width: float = None, \n",
    "                          return_skeleton: bool = False,\n",
    "                          normalize_angle_min: float = 0.0, normalize_angle_delta: float = 1.0,\n",
    "                          normalize_distance_min: float = 0.0, normalize_distance_delta: float = 1.0,\n",
    "                          normalize_width_min: float = 0.0, normalize_width_delta: float = 1.0):\n",
    "    \"\"\" \n",
    "        Takes a binary mask and computes a representation in (distance, angle, width)-space.\n",
    "            - distance is the distance of each pixel to the closest pixel on the skeleton (= center of road)\n",
    "            - angle is the angle to the closest pixel on the skeleton (= center of road)\n",
    "            - width is the width of the mask at the closest pixel on the skeleton (= center of road)\n",
    "\n",
    "        Returns the computed representation as a tuple (individual masks have the same size as the original)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        mask\n",
    "            A grayscale image (as numpy array)\n",
    "        padding\n",
    "            By how many pixels should the mask be extended when computing the skeleton (stabilizes boundaries)\n",
    "        smooth_mask_iterations\n",
    "            How often should closing (dilation followed by erosion) be applied to the image? \n",
    "            (can improve skeleton quality by smoothing edges)\n",
    "        smooth_angle\n",
    "            stddev to use for gaussian blurring of angle mask\n",
    "        smooth_width\n",
    "            stddev to use for gaussian blurring of width mask\n",
    "        return_skeleton\n",
    "            Should the intermediate skeleton be returned as well\n",
    "        normalize_<r|angle|width>_mean:\n",
    "            Mean of distribution (will be subtracted)\n",
    "        normalize_<r|angle|width>_std:\n",
    "            Standard deviation of distribution (will divide by this)\n",
    "    \"\"\"\n",
    "    original_mask = mask\n",
    "    mask = F.pad(torch.Tensor(mask).unsqueeze(0), pad=(padding,padding,padding,padding), mode='replicate').squeeze().numpy()\n",
    "\n",
    "    # removes minor edges that cause additional branch in skeleton\n",
    "    mask = binary_closing(mask, iterations=smooth_mask_iterations)\n",
    "    mask = 1.0 * mask # convert to float\n",
    "\n",
    "    # perform skeletonization\n",
    "    skeleton = skeletonize(mask, method='zhang') # lee does not work for lower resolutions\n",
    "    # skeleton = medial_axis(mask) # medial_axis does not work as good for lower resolution!\n",
    "\n",
    "    # compute distance to edge of road\n",
    "    # dist_to_edge = distance_transform_edt(binary_erosion(mask))\n",
    "    outline = mask - binary_erosion(mask) # using this, so we don't lose very thin connections\n",
    "    dist_to_edge = distance_transform_edt(1.0 - outline)\n",
    "\n",
    "    # compute distance to center of road\n",
    "    distance, idx_center = distance_transform_edt(1.0 - skeleton, return_indices=True)\n",
    "\n",
    "    # the width of the road a pixel belongs to\n",
    "    h,w = mask.shape\n",
    "    width = np.zeros(shape=(h,w))\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            width[y,x] = dist_to_edge[idx_center[0][y,x], idx_center[1][y,x]]\n",
    "\n",
    "    if smooth_width:\n",
    "        width = gaussian_filter(width, smooth_width)\n",
    "\n",
    "    h,w = distance.shape\n",
    "    grid = np.linspace(0,h-1,h).reshape(h,1)\n",
    "    y = idx_center[0] - grid\n",
    "    x = idx_center[1] - grid.T\n",
    "\n",
    "    c = x+1j * y\n",
    "    angle = anglef(c)\n",
    "    if smooth_angle:\n",
    "        angle = gaussian_filter(angle, smooth_angle)\n",
    "    \n",
    "    # d = abs(c) # does not improve quality\n",
    "\n",
    "    # if mask is empty\n",
    "    if not mask[mask > 0].any(): \n",
    "        angle = np.ones_like(mask) * normalize_angle_delta * 0.5 + normalize_angle_min # unknown, so set to mean\n",
    "        width = np.ones_like(mask) * normalize_width_delta * 0.5 + normalize_width_min # unknown, so set to mean\n",
    "        distance = np.ones_like(mask) * normalize_distance_delta + normalize_distance_min # guaranteed to be large\n",
    "\n",
    "    distance = distance[padding:-padding, padding:-padding]\n",
    "    angle = angle[padding:-padding, padding:-padding]\n",
    "    width = width[padding:-padding, padding:-padding]\n",
    "\n",
    "    # normalization\n",
    "    distance = (distance - normalize_distance_min) / normalize_distance_delta\n",
    "    angle = (angle - normalize_angle_min) / normalize_angle_delta\n",
    "    width = (width - normalize_width_min) / normalize_width_delta\n",
    "\n",
    "    if not return_skeleton:\n",
    "        return distance, angle, width\n",
    "    else:\n",
    "        skeleton = skeleton[padding:-padding, padding:-padding]\n",
    "        return distance, angle, width, skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = os.path.join(DATASET_FOLDER, 'groundtruth')\n",
    "output_folder = os.path.join(DATASET_FOLDER, 'transformed')\n",
    "\n",
    "m_folder = os.path.join(output_folder, 'mask')\n",
    "os.makedirs(m_folder, exist_ok=True)\n",
    "a_folder = os.path.join(output_folder, 'angle')\n",
    "os.makedirs(a_folder, exist_ok=True)\n",
    "d_folder = os.path.join(output_folder, 'distance')\n",
    "os.makedirs(d_folder, exist_ok=True)\n",
    "w_folder = os.path.join(output_folder, 'width')\n",
    "os.makedirs(w_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(i, img_name):\n",
    "    full_path = os.path.join(input_folder, img_name)\n",
    "    descriptor = img_name.split('.')[0]\n",
    "    mask = torchvision.io.read_image(full_path, mode=ImageReadMode.GRAY)/255.0\n",
    "    original_shape = (mask.shape[1], mask.shape[2])\n",
    "    mask = F.interpolate(input=mask.unsqueeze(0), size=TARGET_SIZE).squeeze(0)\n",
    "    mask = mask.squeeze().numpy()\n",
    "\n",
    "    distance, angle, width = mask_to_distance_angle_width(\n",
    "        mask, padding=PADDING, smooth_angle=SMOOTH_ANGLE, smooth_width=SMOOTH_WIDTH, smooth_mask_iterations=SMOOTH_MASK_ITERATIONS,\n",
    "        normalize_angle_min=NORM_ANGLE_MIN, normalize_angle_delta=NORM_ANGLE_DELTA, \n",
    "        normalize_distance_min=NORM_DISTANCE_MIN, normalize_distance_delta=NORM_DISTANCE_DELTA,\n",
    "        normalize_width_min=NORM_WIDTH_MIN, normalize_width_delta=NORM_WIDTH_DELTA\n",
    "    )\n",
    "\n",
    "    # ensure the masks are properly normalized\n",
    "    assert mask.min() >= 0 and mask.max() <= 1.0, f\"invalid mask value for {descriptor} {mask.min()} {mask.max()}\"\n",
    "    assert angle.min() >= 0 and angle.max() <= 1.0, f\"invalid angle value for {descriptor} {angle.min()} {angle.max()}\"\n",
    "    assert distance.min() >= 0 and distance.max() <= 1.0, f\"invalid distance value for {descriptor} {distance.min()} {distance.max()}\"\n",
    "    assert width.min() >= 0 and width.max() <= 1.0, f\"invalid width value for {descriptor} {width.min()} {width.max()}\"\n",
    "\n",
    "    mask = torch.tensor(mask * 255, dtype=torch.uint8).unsqueeze(0)\n",
    "    angle = torch.tensor(angle * 255, dtype=torch.uint8).unsqueeze(0)\n",
    "    distance = torch.tensor(distance * 255, dtype=torch.uint8).unsqueeze(0)\n",
    "    width = torch.tensor(width * 255, dtype=torch.uint8).unsqueeze(0)\n",
    "\n",
    "    mask = F.interpolate(mask.unsqueeze(0), original_shape, mode='nearest').squeeze(0)\n",
    "    angle = F.interpolate(angle.unsqueeze(0), original_shape, mode='nearest').squeeze(0)\n",
    "    distance = F.interpolate(distance.unsqueeze(0), original_shape, mode='nearest').squeeze(0)\n",
    "    width = F.interpolate(width.unsqueeze(0), original_shape, mode='nearest').squeeze(0)\n",
    "\n",
    "    # save\n",
    "    torchvision.io.write_png(mask, os.path.join(m_folder, f'{descriptor}.png'))\n",
    "    torchvision.io.write_png(angle, os.path.join(a_folder, f'{descriptor}.png'))\n",
    "    torchvision.io.write_png(distance, os.path.join(d_folder, f'{descriptor}.png'))\n",
    "    torchvision.io.write_png(width, os.path.join(w_folder, f'{descriptor}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Parallel(n_jobs=8)(delayed(process)(i, img_name) for i,img_name in enumerate(os.listdir(input_folder)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish Normalization Constants\n",
    "0-1 normalization is important because the distances and widths are much larger than the angles, which will cause problems with the gradients during training.\n",
    "Use the following code to establish which constants to use for std-norm normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "angles = []\n",
    "widths = []\n",
    "\n",
    "input_folder = 'data/training/groundtruth'\n",
    "for i,img_name in enumerate(os.listdir(input_folder)):\n",
    "    full_path = os.path.join(input_folder, img_name)\n",
    "    descriptor = img_name.split('.')[0]\n",
    "    mask = torchvision.io.read_image(full_path, mode=ImageReadMode.GRAY)/255.0\n",
    "    mask = F.interpolate(input=mask.unsqueeze(0), size=TARGET_SIZE).squeeze(0)\n",
    "    mask = mask.squeeze().numpy()\n",
    "\n",
    "    distance, angle, width = mask_to_distance_angle_width(mask, padding=PADDING, smooth_angle=SMOOTH_ANGLE, smooth_width=SMOOTH_WIDTH)\n",
    "    \n",
    "    distances.append(distance)\n",
    "    angles.append(angle)\n",
    "    widths.append(width)\n",
    "\n",
    "    madw = np.stack([mask, angle, distance, width]).astype(np.float16)\n",
    "\n",
    "distances = np.array(distances).flatten()\n",
    "angles = np.array(angles).flatten()\n",
    "widths = np.array(widths).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"angles: {angles.mean()}, {angles.std()}\")\n",
    "print(f\"distances: {distances.mean()}, {distances.std()}\")\n",
    "print(f\"widths: {widths.mean()}, {widths.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "In the following section, the transformation is qualitatively inspected and the susceptibility to noise is measured through a naive reconstruction algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torchvision.io.read_image('data/data1k/groundtruth/boston_satimage_163.png', mode=ImageReadMode.GRAY)/255.0\n",
    "dist,angle,width,skeleton = mask_to_distance_angle_width(mask, PADDING, SMOOTH_MASK_ITERATIONS, SMOOTH_ANGLE, SMOOTH_WIDTH, True, NORM_ANGLE_MIN, NORM_ANGLE_DELTA, NORM_DISTANCE_MIN, NORM_DISTANCE_DELTA, NORM_WIDTH_MIN, NORM_WIDTH_DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[0])\n",
    "plt.show()\n",
    "plt.imshow(angle)\n",
    "plt.show()\n",
    "plt.imshow(dist)\n",
    "plt.show()\n",
    "plt.imshow(width)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_naive(weight,distance,angle,width,padding=25):\n",
    "    # does naive reconstruction using pointwise additive voting\n",
    "    h,w = distance.shape\n",
    "    ph,pw = 2*padding+h, 2*padding+w\n",
    "    cartesian_center = distance * np.exp(1j * angle) # relative cartesian coordinates of center\n",
    "\n",
    "    grid = np.linspace(0,h-1,h).reshape(h,1)\n",
    "    cartesian_center += (padding + grid.T) + 1j * (padding + grid)\n",
    "    center_y = imag(cartesian_center)\n",
    "    center_x = real(cartesian_center)\n",
    "\n",
    "    # Crop to bounds\n",
    "    center_y[center_y < 0] = 0\n",
    "    center_y[center_y >= ph] = ph - 1\n",
    "    center_x[center_x < 0] = 0\n",
    "    center_x[center_x >= pw] = pw - 1\n",
    "\n",
    "    votes = np.zeros(shape=(ph,pw,2))\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            cy = int(center_y[y,x])\n",
    "            cx = int(center_x[y,x])\n",
    "            \n",
    "            votes[cy,cx,0] += weight[y,x] * width[y,x]\n",
    "            votes[cy,cx,1] += weight[y,x]\n",
    "\n",
    "    avg = votes[:,:,0] / votes[:,:,1]\n",
    "    avg[np.isnan(avg)] = 0.0\n",
    "\n",
    "    out = Image.new(mode='L', size=(ph,pw))\n",
    "    out_d = draw.Draw(out)\n",
    "\n",
    "    for y in range(ph):\n",
    "        for x in range(pw):\n",
    "            distance = round(avg[y,x])\n",
    "            out_d.ellipse(xy=((x-distance,y-distance), (x+distance,y+distance)), fill=255)\n",
    "\n",
    "    out = np.array(out) / 255.0\n",
    "    return out[padding:-padding, padding:-padding]\n",
    "\n",
    "# does not require a mask because we treat each center that was only voted for by < min_vote_threshold as an outlier\n",
    "def reconstruct_naive_no_mask(distance, angle, width, padding=25, min_vote_threshold=5):\n",
    "    h,w = distance.shape\n",
    "    ph,pw = 2*padding+h, 2*padding+w\n",
    "    cartesian_center = distance * np.exp(1j * angle) # relative cartesian coordinates of center\n",
    "\n",
    "    grid = np.linspace(0,h-1,h).reshape(h,1)\n",
    "    cartesian_center += (padding + grid.T) + 1j * (padding + grid)\n",
    "    center_y = imag(cartesian_center)\n",
    "    center_x = real(cartesian_center)\n",
    "\n",
    "    # Crop to bounds\n",
    "    center_y[center_y < 0] = 0\n",
    "    center_y[center_y >= ph] = ph - 1\n",
    "    center_x[center_x < 0] = 0\n",
    "    center_x[center_x >= pw] = pw - 1\n",
    "\n",
    "    total_width = np.zeros(shape=(ph,pw))\n",
    "    nr_votes = np.zeros(shape=(ph,pw))\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            cy = int(center_y[y,x])\n",
    "            cx = int(center_x[y,x])\n",
    "            \n",
    "            total_width[cy,cx] += width[y,x]\n",
    "            nr_votes[cy,cx] += 1.0\n",
    "\n",
    "    avg = total_width / nr_votes # the average voted width at each pixel\n",
    "    avg[np.isnan(avg)] = 0.0\n",
    "\n",
    "    out = Image.new(mode='L', size=(ph,pw))\n",
    "    out_d = draw.Draw(out)\n",
    "\n",
    "    for y in range(ph):\n",
    "        for x in range(pw):\n",
    "            distance = round(avg[y,x])\n",
    "            if nr_votes[y,x] > min_vote_threshold:\n",
    "                out_d.ellipse(xy=((x-distance,y-distance), (x+distance,y+distance)), fill=255)\n",
    "\n",
    "    out = np.array(out) / 255.0\n",
    "    return out[padding:-padding, padding:-padding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad examples: 0, 69, 143\n",
    "mask = torchvision.io.read_image('data/training/groundtruth/satimage_53.png', mode=ImageReadMode.GRAY)/255\n",
    "mask = F.interpolate(input=mask.unsqueeze(0), size=TARGET_SIZE).squeeze(0)\n",
    "mask = mask.squeeze().numpy()\n",
    "\n",
    "distance, angle, width, skeleton = mask_to_distance_angle_width(mask, padding=PADDING, smooth_angle=SMOOTH_ANGLE, smooth_width=SMOOTH_WIDTH, return_skeleton=True)\n",
    "#out = reconstruct_naive(mask, r, angle, width, padding=pad) # only use this if we have good quality masks from the model\n",
    "# plt.imshow(reconstruct_naive(np.rot90(distance), np.rot90(angle), np.rot90(width), padding=pad, min_vote_threshold=7))\n",
    "# plt.show()\n",
    "\n",
    "out = reconstruct_naive_no_mask(distance, angle, width, padding=PADDING, min_vote_threshold=7)\n",
    "\n",
    "\n",
    "# display results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(6, 6))\n",
    "\n",
    "h,w = out.shape\n",
    "rgb = np.zeros(shape=(h,w,3))\n",
    "rgb[:,:,0] = mask\n",
    "rgb[:,:,1] = out\n",
    "rgb[:,:,2] = mask\n",
    "\n",
    "axes[0,0].imshow(mask, cmap=plt.cm.gray)\n",
    "axes[0,0].axis('off')\n",
    "axes[0,0].set_title('original', fontsize=10)\n",
    "\n",
    "axes[0,1].imshow(skeleton, cmap=plt.cm.gray)\n",
    "axes[0,1].axis('off')\n",
    "axes[0,1].set_title('skeleton', fontsize=10)\n",
    "\n",
    "axes[0,2].imshow(rgb, cmap='gray')\n",
    "axes[0,2].axis('off')\n",
    "axes[0,2].set_title('Reconstructed Vs Mask\\n(pink=FN, green=FP)', fontsize=10)\n",
    "\n",
    "axes[1,0].imshow(distance * mask, cmap=plt.cm.gray)\n",
    "axes[1,0].axis('off')\n",
    "axes[1,0].set_title('masked distance to center', fontsize=10)\n",
    "\n",
    "axes[1,1].imshow(angle, cmap=plt.cm.gray)\n",
    "axes[1,1].axis('off')\n",
    "axes[1,1].set_title('angle', fontsize=10)\n",
    "\n",
    "axes[1,2].imshow(width * mask, cmap=plt.cm.gray)\n",
    "axes[1,2].axis('off')\n",
    "axes[1,2].set_title('masked width', fontsize=10)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction With Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "h,w = distance.shape\n",
    "noise = lambda min,max: random.random(size=(h,w)) * (max - min) + min\n",
    "snoise = lambda v: noise(-v,v)\n",
    "\n",
    "def plot_error(ax,title,out):\n",
    "    rgb = np.zeros(shape=(h,w,3))\n",
    "    rgb[:,:,0] = mask\n",
    "    rgb[:,:,1] = out\n",
    "    rgb[:,:,2] = mask\n",
    "\n",
    "    ax.imshow(rgb)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title, fontsize=10)\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(8, 8))\n",
    "\n",
    "axes[0,0].imshow(mask, cmap=plt.cm.gray)\n",
    "axes[0,0].axis('off')\n",
    "axes[0,0].set_title('original', fontsize=10)\n",
    "axes[0,1].axis('off')\n",
    "axes[0,2].axis('off')\n",
    "axes[0,3].axis('off')\n",
    "axes[0,4].axis('off')\n",
    "\n",
    "plot_error(axes[1,0], 'distance 0.5',  reconstruct_naive_no_mask(distance + snoise(0.5), angle, width, padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[1,1], 'distance 1',    reconstruct_naive_no_mask(distance + snoise(1.0), angle, width, padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[1,2], 'distance 3',    reconstruct_naive_no_mask(distance + snoise(3.0), angle, width, padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[1,3], 'distance 10',   reconstruct_naive_no_mask(distance + snoise(10.0), angle, width, padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[1,4], 'distance 25',   reconstruct_naive_no_mask(distance + snoise(25.0), angle, width, padding=PADDING, min_vote_threshold=7))\n",
    "\n",
    "plot_error(axes[2,0], 'angle 0.01',     reconstruct_naive_no_mask(distance, angle + snoise(0.01), width, padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[2,1], 'angle 0.1',      reconstruct_naive_no_mask(distance, angle + snoise(0.1), width, padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[2,2], 'angle 0.33',     reconstruct_naive_no_mask(distance, angle + snoise(0.33), width, padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[2,3], 'angle 1.0',      reconstruct_naive_no_mask(distance, angle + snoise(1.0), width, padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[2,4], 'angle 10.0',     reconstruct_naive_no_mask(distance, angle + snoise(10.0), width, padding=PADDING, min_vote_threshold=7))\n",
    "\n",
    "\n",
    "plot_error(axes[3,0], 'width 0.5',  reconstruct_naive_no_mask(distance, angle, width + snoise(0.5), padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[3,1], 'width 1',    reconstruct_naive_no_mask(distance, angle, width + snoise(1.0), padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[3,2], 'width 5',    reconstruct_naive_no_mask(distance, angle, width + snoise(5.0), padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[3,3], 'width 10',   reconstruct_naive_no_mask(distance, angle, width + snoise(10.0), padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[3,4], 'width 30',   reconstruct_naive_no_mask(distance, angle, width + snoise(30.0), padding=PADDING, min_vote_threshold=7))\n",
    "\n",
    "plot_error(axes[4,0], 'all very little',    reconstruct_naive_no_mask(distance + snoise(0.5), angle + snoise(0.01), width + snoise(0.5), padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[4,1], 'all little',         reconstruct_naive_no_mask(distance + snoise(1.0), angle + snoise(0.1), width + snoise(1.0), padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[4,2], 'all medium',         reconstruct_naive_no_mask(distance + snoise(3.0), angle + snoise(0.33), width + snoise(5.0), padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[4,3], 'all much',           reconstruct_naive_no_mask(distance + snoise(10.0), angle + snoise(1.0), width + snoise(10.0), padding=PADDING, min_vote_threshold=7))\n",
    "plot_error(axes[4,4], 'all very much',      reconstruct_naive_no_mask(distance + snoise(25.0), angle + snoise(10.0), width + snoise(30.0), padding=PADDING, min_vote_threshold=7))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
